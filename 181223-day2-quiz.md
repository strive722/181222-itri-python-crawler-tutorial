# 181222-day2-quiz

## 1. 為什麼 Python 程式語言要分成 Python2, Python3 不同的版本，使用上有什麼問題？
      Print為例

在 Python 2 中， print 被视为一个语句而不是一个函数，这是一个典型的容易弄混的地方，因为在 Python 中的许多操作都需要括号内的参数来执行。如果在 Python 2 中你想要你的控制台输出 ”Sammy the Shark is my favorite sea creature”，你应该写下这样的 print 语句：

1 print "Sammy the Shark is my favorite sea creature"

在使用 Python 3 时，print（）会被显式地视为一个函数，因此要输出上面相同的字符串，你可以使用这种非常简单且易于使用的函数语法：
1 print("Sammy the Shark is my favorite sea creature")
这种改变使得 Python 的语法更加一致，并且在不同的 print 函数之间进行切换更加容易。就方便性而言，print（）语法也与 Python 2.7 向后兼容，因此您的 Python 3 print（）函数可以在任一版本中运行。
      
## 2. 完成以下填空：

- 使用者在看瀏覽網站的操作行為，使基於【HTTP】  協定：
- 使用者在瀏覽器上輸入網址…
- [使用者/Client side] 發送 【Request】 給 [網站伺服器/ Server side]
- [網站伺服器/ Server side] 回傳 【Response＿】給 [使用者/Client side] 瀏覽器將內容處理之後顯示給使用者…

## 3. 請問動態網頁爬蟲跟靜態網頁爬蟲主要的差別是什麼？
       靜態網頁，表示網頁是在 Server-side 就已經產生回來的，所 以你看的網頁上的資料是固定的（除非重新要求 Server-side）。這樣 時候，我們可以來解析一下那資料，網頁，瀏覽器，是怎麼被串起來 的呢？一般來說流程是這樣：
§使用者（Client-side）發出請求，稱為是 Request。 §伺服器（Server-side）收到請求，根據請求處理後回應，稱為是 Response。 §產生的回應如果是純資料的話，屬於 API 的一種；如果是網頁的話， 就會回傳一個包含 HTML 標籤的網頁格式。 §瀏覽器接收包含 HTML 標籤的網頁格式，呈現網頁給使用者。
       動態網頁取得資料流程是這樣： § 使用者（Client-side）發出請求，稱為是Request。 § 伺服器（Server-side）收到請求，根據請求處理後回應，稱為是Response。 § 產生的回應如果是純資料的話，屬於API 的一種；如果是網頁的話，就會回 傳一個包含HTML 標籤的網頁格式。 § 瀏覽器接收包含HTML 標籤的網頁格式，呈現網頁給使用者。=> 此時是 還沒有資料的！ § 當瀏覽器解析HTML 後，開始運行JavaScript 時會動態的呼叫API Request 取得資料。=> 真的有資料了～ § 瀏覽器中的JavaScript 會將資料更新到現有的HTML 上，呈現網頁給使用者。

 
      動態網頁與靜態網頁最大的不同是資料是在什麼時間點取得的。 動態網頁是在瀏覽器已經取得HTML 後，才透過JavaScript 在 需要時動態地取得資料。因此，爬蟲程式也必須要考慮動態取得 資料這件事情，才有辦法正確地找到想要的資料

## 4.動態網頁爬蟲跟靜態網頁爬蟲的爬蟲策略有什麼差別?
    靜態網頁爬蟲策略就是一個網頁形成及溝通的過程。網路爬蟲，簡單來說， 就是模擬使用者的行為，把資料做一個攔截的動作。基本上可以 簡化為：
[模擬Request] -> [攔截Response] -> [從Response 整理資料] > [done!]
    動態網頁爬蟲策略
    方法一：Selenium+ BS4
§Selenium + BS4 => 模擬使用者從「發出Request」到 「JavaScript 動態載入資料」的過程，也就是step1 -step6 的 動作
163
方法二：Request + API
§Request + API => 模擬「JavaScript 動態載入資料」的過程， 也就是step5 的動作


        
## 5. 找一個網站，說明哪些內容是可以透過靜態方式取得？哪些是需要透過動態方式取得？
     
      
## 6. 實作題：利用 Yahoo! 電影，取出本週熱門新片的「中英文名稱」、「上映日期」、「期待度」、「滿意度」，還有「封面照片網址」，並印出。用一個你覺得適合的型態存到一個變數內。

```
# 請將程式碼貼在這裡
```

from bs4 import BeautifulSoup
   
url = 'https://movies.yahoo.com.tw/movie_thisweek.html?}'
r = requests.get(url)
soup = BeautifulSoup(r.text, 'html.parser')
movise = []
imgs = []
for d in soup.find_all(class_="release_info"):

    dictstr= {}
    dictstr['中文名稱']=(d.find(class_="release_info_text").find(class_="release_movie_name").find(class_="gabtn").text.replace(' ', '').replace('\n', ''))
    dictstr['英文名稱']=(d.find(class_="release_info_text").find(class_="en").find(class_="gabtn").text.replace(' ', '').replace('\n', ''))
    dictstr['期待度']=(d.find(class_="release_info_text").find(class_="release_movie_time").text.replace(' ', '').replace('\n', ''))
    dictstr['滿意度']=(d.find(class_="release_info_text").find(class_="leveltext").text.replace(' ', '').replace('\n', ''))
    dictstr['上映時間']=(d.find(class_="release_info_text").find(class_="release_movie_time").text.replace(' ', '').replace('\n', ''))
    movise.append(dictstr)

import urllib.request    
for ds in soup.find_all(class_="release_foto"):
    dictimagestr= {}
    
    dictimagestr['封面照片網址']=(ds.a.img['src'])
    imgs.append(dictimagestr)
res = []
for i,j in zip(movise, imgs):
    res.append(dict(list(i.items()) + list(j.items())))
print (res)

## 7. 實作題：利用 104 人力銀行，計算出台中市用「資料」關鍵字可以找到的公司數量有幾個？

```
# 請將程式碼貼在這裡
```
from bs4 import BeautifulSoup

headers = {
    'Accept': 'application/json, text/javascript, */*; q=0.01',
    'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7,zh-CN;q=0.6,ja;q=0.5',
    'Connection': 'keep-alive',
    'Cookie': 'luauid=2108599161; _ga=GA1.3.696827056.1517415692; __auc=ed4a51af1614d05f6d120b43bfb; PERSONAL_SORT=B; SYS_SETAB=20140613; _T_MYPOOL_104I=3; 104i_viewJobJobHistory=%5B%224nm6l%22%2C%223i8q6%22%5D; _gid=GA1.3.516194520.1528488749; __asc=bb64e596163e2c7db70da629853; lup=2108599161.5057323988685.4690104285048.1.4507568175053; lunp=4690104285048',
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36',
    'X-Requested-With': 'XMLHttpRequest',
    'Host': 'www.104.com.tw',
    'Referer': 'https://www.104.com.tw/cust/list/index/'
}
count  =0
for p in range(1, 10):
    url = f'https://www.104.com.tw/cust/list/ajax/index?page={p}&keyword=%E8%B3%87%E6%96%99&area=6001008000&order=1&mode=s&jobsource=checkc'
    r = requests.get(url, headers=headers)
    r.encoding = 'utf-8'
    data = json.loads(r.text)['data']['list']      
    for d in data:
        count =count+1
print('一共有公司:',count,'家')




